{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import datetime, logging, os, sys, math, random\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from keras import Sequential, layers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2 as cv\n",
    "from PIL import Image as Img\n",
    "import numba\n",
    "\n",
    "\n",
    "import pickle \n",
    "import albumentations as A\n",
    "\n",
    "from ImageDataAugmentor.image_data_augmentor import *\n",
    "from albumentations.core.composition import Compose, OneOf\n",
    "from albumentations.core.transforms_interface import ImageOnlyTransform\n",
    "\n",
    "devices = tf.config.list_physical_devices('GPU')\n",
    "for device in devices:\n",
    "   tf.config.experimental.set_memory_growth(device, True) \n",
    "print(devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/sorghum-id-2022-04-30-124425-EfficientNetV2L-imagenet/EfficientNetV2L-optimal.h5\n"
     ]
    }
   ],
   "source": [
    "PATH = os.path.abspath(os.path.join(os.getcwd() ,\"../../../../datasets/sorghum-id-fgvc-9\"))+\"/\"\n",
    "\n",
    "MODEL_FOLDER = \"sorghum-id-2022-04-30-124425-EfficientNetV2L-imagenet\" #### CHANGE ME\n",
    "MODEL_NAME   = \"EfficientNetV2L-optimal.h5\"\n",
    "MODEL_PATH = \"../models/\"+MODEL_FOLDER+\"/\"+MODEL_NAME\n",
    "\n",
    "test_dir = PATH+'test/'\n",
    "save_dir    = '../results/sorghum/tta/'\n",
    "\n",
    "print(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"../labels.pkl\",\"rb\")\n",
    "labels = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>cultivar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000005362.png</td>\n",
       "      <td>PI_152923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000099707.png</td>\n",
       "      <td>PI_152923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000135300.png</td>\n",
       "      <td>PI_152923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000136796.png</td>\n",
       "      <td>PI_152923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000292439.png</td>\n",
       "      <td>PI_152923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23634</th>\n",
       "      <td>999578153.png</td>\n",
       "      <td>PI_152923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23635</th>\n",
       "      <td>999692877.png</td>\n",
       "      <td>PI_152923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23636</th>\n",
       "      <td>999756998.png</td>\n",
       "      <td>PI_152923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23637</th>\n",
       "      <td>999892248.png</td>\n",
       "      <td>PI_152923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23638</th>\n",
       "      <td>999945922.png</td>\n",
       "      <td>PI_152923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23639 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             filename   cultivar\n",
       "0      1000005362.png  PI_152923\n",
       "1      1000099707.png  PI_152923\n",
       "2      1000135300.png  PI_152923\n",
       "3      1000136796.png  PI_152923\n",
       "4      1000292439.png  PI_152923\n",
       "...               ...        ...\n",
       "23634   999578153.png  PI_152923\n",
       "23635   999692877.png  PI_152923\n",
       "23636   999756998.png  PI_152923\n",
       "23637   999892248.png  PI_152923\n",
       "23638   999945922.png  PI_152923\n",
       "\n",
       "[23639 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WIDTH = 512\n",
    "HEIGHT = 512\n",
    "\n",
    "submission = pd.read_csv(PATH+'sample_submission.csv')\n",
    "\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clahe(img):\n",
    "    c = cv.createCLAHE(clipLimit=40, tileGridSize=(16,16))  # create a clahe object\n",
    "    t = np.asarray(img)                                     # convert to np array\n",
    "    t = cv.cvtColor(t, cv.COLOR_BGR2HSV)                    # convert to OpenCV HSV\n",
    "    t[:,:,-1] = c.apply(t[:,:,-1])                          # Apply CLAHE to the Value (greyscale) of the image\n",
    "    t = cv.cvtColor(t, cv.COLOR_HSV2BGR)                    # Return to BGR OpenCV doamin\n",
    "    t = Img.fromarray(t)                                    # Convert to PIL Image\n",
    "    t = np.array(t)                                         # back to np array\n",
    "    return t\n",
    "\n",
    "def normalise(img):\n",
    "    t = np.array(img,dtype=np.float32)/255\n",
    "    return t\n",
    "\n",
    "class CLAHE(ImageOnlyTransform):\n",
    "    def apply(self, img, **params):\n",
    "        return clahe(img)\n",
    "\n",
    "class NORMALISE(ImageOnlyTransform):\n",
    "    def apply(self, img, **params):\n",
    "        return normalise(img)\n",
    "\n",
    "def augment_data(phase: str):\n",
    "    if phase == \"train\":\n",
    "        return Compose([\n",
    "                CLAHE(p=1),\n",
    "                A.RandomResizedCrop(height=HEIGHT, width=WIDTH),\n",
    "                A.Flip(p=0.5),\n",
    "                A.RandomRotate90(p=0.5),\n",
    "                A.ShiftScaleRotate(p=0.5),\n",
    "                A.HueSaturationValue(p=0.5),\n",
    "                A.OneOf([\n",
    "                    A.RandomBrightnessContrast(p=0.5),\n",
    "                    A.RandomGamma(p=0.5),\n",
    "                ], p=0.5),\n",
    "                OneOf([\n",
    "                    A.Blur(p=0.1),\n",
    "                    A.GaussianBlur(p=0.1),\n",
    "                    A.MotionBlur(p=0.1),\n",
    "                ], p=0.1),\n",
    "                OneOf([\n",
    "                    A.GaussNoise(p=0.1),\n",
    "                    A.ISONoise(p=0.1),\n",
    "                    A.GridDropout(ratio=0.5, p=0.2),\n",
    "                    A.CoarseDropout(max_holes=16, min_holes=8, max_height=16,\n",
    "                                    max_width=16, min_height=8, min_width=8, p=0.2)\n",
    "                ], p=0.2),\n",
    "                #A.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225], max_pixel_value=255.0),\n",
    "                \n",
    "        ])\n",
    "    else:\n",
    "        return Compose([\n",
    "                CLAHE(p=1),\n",
    "                A.Resize(height=HEIGHT, width=WIDTH),\n",
    "                #A.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225], max_pixel_value=255.0),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Time Augmentation - Horizontal Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TTA = [\n",
    "        Compose([CLAHE(p=1),\n",
    "                A.Resize(height=HEIGHT, width=WIDTH),]),\n",
    "\n",
    "        Compose([CLAHE(p=1),\n",
    "                A.Resize(height=HEIGHT, width=WIDTH),\n",
    "                A.HorizontalFlip(p=1),]),\n",
    "\n",
    "        # Compose([CLAHE(p=1),\n",
    "        #         A.Resize(height=HEIGHT, width=WIDTH),\n",
    "        #         A.VerticalFlip(p=1),]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"/mnt/shared/scratch/fmacfarl/datasets/sorghum-id-fgvc-9/train_images/2017-06-05__13-04-59-234.png\")\n",
    "#image = cv2.imread(\"/mnt/shared/scratch/fmacfarl/datasets/sorghum-id-fgvc-9/train_images/2017-06-30__12-38-34-583.png\")\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "for aug in TTA:\n",
    "    transformed_image = aug(image=image)[\"image\"]\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    ax = plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    ax = plt.subplot(1, 2, 2)\n",
    "    plt.imshow(transformed_image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without TTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = ImageDataAugmentor(augment=augment_data(\"test\"))\n",
    "test_generator = test_gen.flow_from_dataframe(dataframe=submission,\n",
    "                                              directory=test_dir,\n",
    "                                              x_col='filename',\n",
    "                                              y_col=None,\n",
    "                                              target_size=(WIDTH,HEIGHT),\n",
    "                                              color_mode='rgb',\n",
    "                                              class_mode=None,\n",
    "                                              batch_size=1,\n",
    "                                              shuffle=False,)\n",
    "\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "STEP_SIZE_TEST,test_generator.n,test_generator.batch_size\n",
    "\n",
    "reconstructed_model = tf.keras.models.load_model(MODEL_PATH)\n",
    "\n",
    "%time\n",
    "test_generator.reset()\n",
    "results = reconstructed_model.predict(test_generator,verbose=1,steps=STEP_SIZE_TEST)\n",
    "\n",
    "predicted_class_indices=np.argmax(results,axis=1)\n",
    "labels_dict = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels_dict[k] for k in predicted_class_indices]\n",
    "\n",
    "filenames=test_generator.filenames\n",
    "submission=pd.DataFrame({\"Filename\":[filename.replace('all_classes/','')for filename in filenames],\n",
    "                      \"cultivar\":predictions})\n",
    "\n",
    "submission_name = save_dir+'submission-no-TTA-EfficientNetV2L-imagenet-2022-04-30-124425.csv'\n",
    "submission.to_csv(submission_name,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With TTA and Average Confidence Aggregation\n",
    "\n",
    "### Horizontal Flip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_model = tf.keras.models.load_model(MODEL_PATH)\n",
    "\n",
    "results_aggregated = np.zeros([23639,100],dtype=np.float32)\n",
    "results_collated = np.zeros([23639,100,len(TTA)],dtype=np.float32)\n",
    "\n",
    "submission = pd.read_csv(PATH+'sample_submission.csv')\n",
    "\n",
    "tta_df = pd.DataFrame(index=submission.index)\n",
    "\n",
    "for i, tta in enumerate(TTA):\n",
    "    test_gen = ImageDataAugmentor(augment=tta)\n",
    "    test_generator = test_gen.flow_from_dataframe(dataframe=submission,\n",
    "                                              directory=test_dir,\n",
    "                                              x_col='filename',\n",
    "                                              y_col=None,\n",
    "                                              target_size=(WIDTH,HEIGHT),\n",
    "                                              class_mode=None,\n",
    "                                              batch_size=1,\n",
    "                                              shuffle=False,)\n",
    "\n",
    "    STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "    STEP_SIZE_TEST,test_generator.n,test_generator.batch_size\n",
    "    \n",
    "    test_generator.reset()\n",
    "    # x= test_generator.next()\n",
    "    # image = x[0]\n",
    "    # plt.imshow(image/255)\n",
    "    # plt.show()  \n",
    "    # print(np.max(image),np.min(image))\n",
    "    results = reconstructed_model.predict(test_generator,verbose=1,steps=STEP_SIZE_TEST)\n",
    "    results_collated[:,:,i] = results\n",
    "    results_aggregated += results\n",
    "\n",
    "\n",
    "results_aggregated = results_aggregated/len(TTA)\n",
    "predicted_class_indices=np.argmax(results_aggregated,axis=1)\n",
    "\n",
    "labels_dict = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels_dict[k] for k in predicted_class_indices]\n",
    "\n",
    "filenames=test_generator.filenames\n",
    "submission=pd.DataFrame({\"Filename\":[filename.replace('all_classes/','')for filename in filenames],\n",
    "                      \"cultivar\":predictions})\n",
    "\n",
    "submission_name = save_dir+'submission-TTA-hf-EfficientNetV2L-imagenet-2022-04-30-124425.csv'\n",
    "submission.to_csv(submission_name,index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vertical Flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TTA = [\n",
    "        Compose([CLAHE(p=1),\n",
    "                A.Resize(height=HEIGHT, width=WIDTH),]),\n",
    "\n",
    "        # Compose([CLAHE(p=1),\n",
    "        #         A.Resize(height=HEIGHT, width=WIDTH),\n",
    "        #         A.HorizontalFlip(p=1),]),\n",
    "\n",
    "        Compose([CLAHE(p=1),\n",
    "                A.Resize(height=HEIGHT, width=WIDTH),\n",
    "                A.VerticalFlip(p=1),]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_model = tf.keras.models.load_model(MODEL_PATH)\n",
    "\n",
    "results_aggregated = np.zeros([23639,100],dtype=np.float32)\n",
    "results_collated = np.zeros([23639,100,len(TTA)],dtype=np.float32)\n",
    "\n",
    "submission = pd.read_csv(PATH+'sample_submission.csv')\n",
    "\n",
    "tta_df = pd.DataFrame(index=submission.index)\n",
    "\n",
    "for i, tta in enumerate(TTA):\n",
    "    test_gen = ImageDataAugmentor(augment=tta)\n",
    "    test_generator = test_gen.flow_from_dataframe(dataframe=submission,\n",
    "                                              directory=test_dir,\n",
    "                                              x_col='filename',\n",
    "                                              y_col=None,\n",
    "                                              target_size=(WIDTH,HEIGHT),\n",
    "                                              class_mode=None,\n",
    "                                              batch_size=1,\n",
    "                                              shuffle=False,)\n",
    "\n",
    "    STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "    STEP_SIZE_TEST,test_generator.n,test_generator.batch_size\n",
    "    \n",
    "    test_generator.reset()\n",
    "    # x= test_generator.next()\n",
    "    # image = x[0]\n",
    "    # plt.imshow(image/255)\n",
    "    # plt.show()  \n",
    "    # print(np.max(image),np.min(image))\n",
    "    results = reconstructed_model.predict(test_generator,verbose=1,steps=STEP_SIZE_TEST)\n",
    "    results_collated[:,:,i] = results\n",
    "    results_aggregated += results\n",
    "\n",
    "\n",
    "results_aggregated = results_aggregated/len(TTA)\n",
    "predicted_class_indices=np.argmax(results_aggregated,axis=1)\n",
    "\n",
    "labels_dict = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels_dict[k] for k in predicted_class_indices]\n",
    "\n",
    "filenames=test_generator.filenames\n",
    "submission=pd.DataFrame({\"Filename\":[filename.replace('all_classes/','')for filename in filenames],\n",
    "                      \"cultivar\":predictions})\n",
    "\n",
    "submission_name = save_dir+'submission-TTA-vf-EfficientNetV2L-imagenet-2022-04-30-124425.csv'\n",
    "submission.to_csv(submission_name,index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Horizontal + Vertical (Individual Flips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TTA = [\n",
    "        Compose([CLAHE(p=1),\n",
    "                A.Resize(height=HEIGHT, width=WIDTH),]),\n",
    "\n",
    "        Compose([CLAHE(p=1),\n",
    "                A.Resize(height=HEIGHT, width=WIDTH),\n",
    "                A.HorizontalFlip(p=1),]),\n",
    "\n",
    "        Compose([CLAHE(p=1),\n",
    "                A.Resize(height=HEIGHT, width=WIDTH),\n",
    "                A.VerticalFlip(p=1),]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_model = tf.keras.models.load_model(MODEL_PATH)\n",
    "\n",
    "results_aggregated = np.zeros([23639,100],dtype=np.float32)\n",
    "results_collated = np.zeros([23639,100,len(TTA)],dtype=np.float32)\n",
    "\n",
    "submission = pd.read_csv(PATH+'sample_submission.csv')\n",
    "\n",
    "tta_df = pd.DataFrame(index=submission.index)\n",
    "\n",
    "for i, tta in enumerate(TTA):\n",
    "    test_gen = ImageDataAugmentor(augment=tta)\n",
    "    test_generator = test_gen.flow_from_dataframe(dataframe=submission,\n",
    "                                              directory=test_dir,\n",
    "                                              x_col='filename',\n",
    "                                              y_col=None,\n",
    "                                              target_size=(WIDTH,HEIGHT),\n",
    "                                              class_mode=None,\n",
    "                                              batch_size=1,\n",
    "                                              shuffle=False,)\n",
    "\n",
    "    STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "    STEP_SIZE_TEST,test_generator.n,test_generator.batch_size\n",
    "    \n",
    "    test_generator.reset()\n",
    "    # x= test_generator.next()\n",
    "    # image = x[0]\n",
    "    # plt.imshow(image/255)\n",
    "    # plt.show()  \n",
    "    # print(np.max(image),np.min(image))\n",
    "    results = reconstructed_model.predict(test_generator,verbose=1,steps=STEP_SIZE_TEST)\n",
    "    results_collated[:,:,i] = results\n",
    "    results_aggregated += results\n",
    "\n",
    "\n",
    "results_aggregated = results_aggregated/len(TTA)\n",
    "predicted_class_indices=np.argmax(results_aggregated,axis=1)\n",
    "\n",
    "labels_dict = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels_dict[k] for k in predicted_class_indices]\n",
    "\n",
    "filenames=test_generator.filenames\n",
    "submission=pd.DataFrame({\"Filename\":[filename.replace('all_classes/','')for filename in filenames],\n",
    "                      \"cultivar\":predictions})\n",
    "\n",
    "submission_name = save_dir+'submission-TTA-hfvf-EfficientNetV2L-imagenet-2022-04-30-124425.csv'\n",
    "submission.to_csv(submission_name,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combinations of Horizontal + Vertical Flips through rotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TTA = [\n",
    "        Compose([CLAHE(p=1),\n",
    "                A.Resize(height=HEIGHT, width=WIDTH),\n",
    "                A.Affine(rotate=0,p=1),]),\n",
    "\n",
    "        # Compose([CLAHE(p=1),\n",
    "        #         A.Resize(height=HEIGHT, width=WIDTH),\n",
    "        #         A.Affine(rotate=90,p=1),]),\n",
    "\n",
    "        Compose([CLAHE(p=1),\n",
    "                A.Resize(height=HEIGHT, width=WIDTH),\n",
    "                A.Affine(rotate=180,p=2),]),\n",
    "        \n",
    "        # Compose([CLAHE(p=1),\n",
    "        #         A.Resize(height=HEIGHT, width=WIDTH),\n",
    "        #         A.Affine(rotate=270,p=3),]),\n",
    "\n",
    "        Compose([CLAHE(p=1),\n",
    "                A.Resize(height=HEIGHT, width=WIDTH),\n",
    "                A.HorizontalFlip(p=1),\n",
    "                A.Affine(rotate=0,p=1),]),\n",
    "\n",
    "        # Compose([CLAHE(p=1),\n",
    "        #         A.Resize(height=HEIGHT, width=WIDTH),\n",
    "        #         A.HorizontalFlip(p=1),\n",
    "        #         A.Affine(rotate=90,p=1),]),\n",
    "\n",
    "        Compose([CLAHE(p=1),\n",
    "                A.Resize(height=HEIGHT, width=WIDTH),\n",
    "                A.HorizontalFlip(p=1),\n",
    "                A.Affine(rotate=180,p=2),]),\n",
    "        \n",
    "        # Compose([CLAHE(p=1),\n",
    "        #         A.Resize(height=HEIGHT, width=WIDTH),\n",
    "        #         A.HorizontalFlip(p=1),\n",
    "        #         A.Affine(rotate=270,p=3),]),\n",
    "\n",
    "        # Compose([CLAHE(p=1),\n",
    "        #         A.Resize(height=HEIGHT, width=WIDTH),\n",
    "        #         A.ShiftScaleRotate(p=1),]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_model = tf.keras.models.load_model(MODEL_PATH)\n",
    "\n",
    "results_aggregated = np.zeros([23639,100],dtype=np.float32)\n",
    "results_collated = np.zeros([23639,100,len(TTA)],dtype=np.float32)\n",
    "\n",
    "submission = pd.read_csv(PATH+'sample_submission.csv')\n",
    "\n",
    "tta_df = pd.DataFrame(index=submission.index)\n",
    "\n",
    "for i, tta in enumerate(TTA):\n",
    "    test_gen = ImageDataAugmentor(augment=tta)\n",
    "    test_generator = test_gen.flow_from_dataframe(dataframe=submission,\n",
    "                                              directory=test_dir,\n",
    "                                              x_col='filename',\n",
    "                                              y_col=None,\n",
    "                                              target_size=(WIDTH,HEIGHT),\n",
    "                                              class_mode=None,\n",
    "                                              batch_size=1,\n",
    "                                              shuffle=False,)\n",
    "\n",
    "    STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "    STEP_SIZE_TEST,test_generator.n,test_generator.batch_size\n",
    "    \n",
    "    test_generator.reset()\n",
    "    # x= test_generator.next()\n",
    "    # image = x[0]\n",
    "    # plt.imshow(image/255)\n",
    "    # plt.show()  \n",
    "    # print(np.max(image),np.min(image))\n",
    "    results = reconstructed_model.predict(test_generator,verbose=1,steps=STEP_SIZE_TEST)\n",
    "    results_collated[:,:,i] = results\n",
    "    results_aggregated += results\n",
    "\n",
    "\n",
    "results_aggregated = results_aggregated/len(TTA)\n",
    "predicted_class_indices=np.argmax(results_aggregated,axis=1)\n",
    "\n",
    "labels_dict = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels_dict[k] for k in predicted_class_indices]\n",
    "\n",
    "filenames=test_generator.filenames\n",
    "submission=pd.DataFrame({\"Filename\":[filename.replace('all_classes/','')for filename in filenames],\n",
    "                      \"cultivar\":predictions})\n",
    "\n",
    "submission_name = save_dir+'submission-TTA-hf+vf-EfficientNetV2L-imagenet-2022-04-30-124425.csv'\n",
    "submission.to_csv(submission_name,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 90 Degree Rotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TTA = [\n",
    "        Compose([CLAHE(p=1),\n",
    "                A.Resize(height=HEIGHT, width=WIDTH),\n",
    "                A.Affine(rotate=0,p=1),]),\n",
    "\n",
    "        Compose([CLAHE(p=1),\n",
    "                A.Resize(height=HEIGHT, width=WIDTH),\n",
    "                A.Affine(rotate=90,p=1),]),\n",
    "\n",
    "        Compose([CLAHE(p=1),\n",
    "                A.Resize(height=HEIGHT, width=WIDTH),\n",
    "                A.Affine(rotate=180,p=2),]),\n",
    "        \n",
    "        Compose([CLAHE(p=1),\n",
    "                A.Resize(height=HEIGHT, width=WIDTH),\n",
    "                A.Affine(rotate=270,p=3),]),\n",
    "\n",
    "        Compose([CLAHE(p=1),\n",
    "                A.Resize(height=HEIGHT, width=WIDTH),\n",
    "                A.HorizontalFlip(p=1),\n",
    "                A.Affine(rotate=0,p=1),]),\n",
    "\n",
    "        Compose([CLAHE(p=1),\n",
    "                A.Resize(height=HEIGHT, width=WIDTH),\n",
    "                A.HorizontalFlip(p=1),\n",
    "                A.Affine(rotate=90,p=1),]),\n",
    "\n",
    "        Compose([CLAHE(p=1),\n",
    "                A.Resize(height=HEIGHT, width=WIDTH),\n",
    "                A.HorizontalFlip(p=1),\n",
    "                A.Affine(rotate=180,p=2),]),\n",
    "        \n",
    "        Compose([CLAHE(p=1),\n",
    "                A.Resize(height=HEIGHT, width=WIDTH),\n",
    "                A.HorizontalFlip(p=1),\n",
    "                A.Affine(rotate=270,p=3),]),\n",
    "\n",
    "        # Compose([CLAHE(p=1),\n",
    "        #         A.Resize(height=HEIGHT, width=WIDTH),\n",
    "        #         A.ShiftScaleRotate(p=1),]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_model = tf.keras.models.load_model(MODEL_PATH)\n",
    "\n",
    "results_aggregated = np.zeros([23639,100],dtype=np.float32)\n",
    "results_collated = np.zeros([23639,100,len(TTA)],dtype=np.float32)\n",
    "\n",
    "submission = pd.read_csv(PATH+'sample_submission.csv')\n",
    "\n",
    "tta_df = pd.DataFrame(index=submission.index)\n",
    "\n",
    "for i, tta in enumerate(TTA):\n",
    "    test_gen = ImageDataAugmentor(augment=tta)\n",
    "    test_generator = test_gen.flow_from_dataframe(dataframe=submission,\n",
    "                                              directory=test_dir,\n",
    "                                              x_col='filename',\n",
    "                                              y_col=None,\n",
    "                                              target_size=(WIDTH,HEIGHT),\n",
    "                                              class_mode=None,\n",
    "                                              batch_size=1,\n",
    "                                              shuffle=False,)\n",
    "\n",
    "    STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "    STEP_SIZE_TEST,test_generator.n,test_generator.batch_size\n",
    "    \n",
    "    test_generator.reset()\n",
    "    # x= test_generator.next()\n",
    "    # image = x[0]\n",
    "    # plt.imshow(image/255)\n",
    "    # plt.show()  \n",
    "    # print(np.max(image),np.min(image))\n",
    "    results = reconstructed_model.predict(test_generator,verbose=1,steps=STEP_SIZE_TEST)\n",
    "    results_collated[:,:,i] = results\n",
    "    results_aggregated += results\n",
    "\n",
    "\n",
    "results_aggregated = results_aggregated/len(TTA)\n",
    "predicted_class_indices=np.argmax(results_aggregated,axis=1)\n",
    "\n",
    "labels_dict = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels_dict[k] for k in predicted_class_indices]\n",
    "\n",
    "filenames=test_generator.filenames\n",
    "submission=pd.DataFrame({\"Filename\":[filename.replace('all_classes/','')for filename in filenames],\n",
    "                      \"cultivar\":predictions})\n",
    "\n",
    "submission_name = save_dir+'submission-TTA-rot-EfficientNetV2L-imagenet-2022-04-30-124425.csv'\n",
    "submission.to_csv(submission_name,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Horizontal Flip, Vertical Flip and a Random Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TTA = [\n",
    "        Compose([CLAHE(p=1),\n",
    "                A.Resize(height=HEIGHT, width=WIDTH),]),\n",
    "\n",
    "        Compose([CLAHE(p=1),\n",
    "                A.Resize(height=HEIGHT, width=WIDTH),\n",
    "                A.HorizontalFlip(p=1),]),\n",
    "\n",
    "        Compose([CLAHE(p=1),\n",
    "                A.Resize(height=HEIGHT, width=WIDTH),\n",
    "                A.VerticalFlip(p=1),]),\n",
    "\n",
    "        Compose([CLAHE(p=1),\n",
    "                A.Resize(height=HEIGHT, width=WIDTH),\n",
    "                A.ShiftScaleRotate(p=1),]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23639 validated image filenames.\n",
      "23639/23639 [==============================] - 1246s 52ms/step\n",
      "Found 23639 validated image filenames.\n",
      "23639/23639 [==============================] - 1260s 53ms/step\n",
      "Found 23639 validated image filenames.\n",
      "23639/23639 [==============================] - 1095s 46ms/step\n",
      "Found 23639 validated image filenames.\n",
      "23639/23639 [==============================] - 1096s 46ms/step\n"
     ]
    }
   ],
   "source": [
    "reconstructed_model = tf.keras.models.load_model(MODEL_PATH)\n",
    "\n",
    "results_aggregated = np.zeros([23639,100],dtype=np.float32)\n",
    "results_collated = np.zeros([23639,100,len(TTA)],dtype=np.float32)\n",
    "\n",
    "submission = pd.read_csv(PATH+'sample_submission.csv')\n",
    "\n",
    "tta_df = pd.DataFrame(index=submission.index)\n",
    "\n",
    "for i, tta in enumerate(TTA):\n",
    "    test_gen = ImageDataAugmentor(augment=tta)\n",
    "    test_generator = test_gen.flow_from_dataframe(dataframe=submission,\n",
    "                                              directory=test_dir,\n",
    "                                              x_col='filename',\n",
    "                                              y_col=None,\n",
    "                                              target_size=(WIDTH,HEIGHT),\n",
    "                                              class_mode=None,\n",
    "                                              batch_size=1,\n",
    "                                              shuffle=False,)\n",
    "\n",
    "    STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "    STEP_SIZE_TEST,test_generator.n,test_generator.batch_size\n",
    "    \n",
    "    test_generator.reset()\n",
    "    # x= test_generator.next()\n",
    "    # image = x[0]\n",
    "    # plt.imshow(image/255)\n",
    "    # plt.show()  \n",
    "    # print(np.max(image),np.min(image))\n",
    "    results = reconstructed_model.predict(test_generator,verbose=1,steps=STEP_SIZE_TEST)\n",
    "    results_collated[:,:,i] = results\n",
    "    results_aggregated += results\n",
    "\n",
    "\n",
    "results_aggregated = results_aggregated/len(TTA)\n",
    "predicted_class_indices=np.argmax(results_aggregated,axis=1)\n",
    "\n",
    "labels_dict = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels_dict[k] for k in predicted_class_indices]\n",
    "\n",
    "filenames=test_generator.filenames\n",
    "submission=pd.DataFrame({\"Filename\":[filename.replace('all_classes/','')for filename in filenames],\n",
    "                      \"cultivar\":predictions})\n",
    "\n",
    "submission_name = save_dir+'submission-TTA-hfvfrot-EfficientNetV2L-imagenet-2022-04-30-124425.csv'\n",
    "submission.to_csv(submission_name,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 90 Degree Rotations and a Ramndom Angle Rotation \n",
    "\n",
    "This may make our predictions worse as camera is mounted on linear translation gantry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TTA = [\n",
    "        Compose([CLAHE(p=1),\n",
    "                A.Resize(height=HEIGHT, width=WIDTH),\n",
    "                A.Affine(rotate=0,p=1),]),\n",
    "\n",
    "        Compose([CLAHE(p=1),\n",
    "                A.Resize(height=HEIGHT, width=WIDTH),\n",
    "                A.Affine(rotate=90,p=1),]),\n",
    "\n",
    "        Compose([CLAHE(p=1),\n",
    "                A.Resize(height=HEIGHT, width=WIDTH),\n",
    "                A.Affine(rotate=180,p=2),]),\n",
    "        \n",
    "        Compose([CLAHE(p=1),\n",
    "                A.Resize(height=HEIGHT, width=WIDTH),\n",
    "                A.Affine(rotate=270,p=3),]),\n",
    "\n",
    "        Compose([CLAHE(p=1),\n",
    "                A.Resize(height=HEIGHT, width=WIDTH),\n",
    "                A.HorizontalFlip(p=1),\n",
    "                A.Affine(rotate=0,p=1),]),\n",
    "\n",
    "        Compose([CLAHE(p=1),\n",
    "                A.Resize(height=HEIGHT, width=WIDTH),\n",
    "                A.HorizontalFlip(p=1),\n",
    "                A.Affine(rotate=90,p=1),]),\n",
    "\n",
    "        Compose([CLAHE(p=1),\n",
    "                A.Resize(height=HEIGHT, width=WIDTH),\n",
    "                A.HorizontalFlip(p=1),\n",
    "                A.Affine(rotate=180,p=2),]),\n",
    "        \n",
    "        Compose([CLAHE(p=1),\n",
    "                A.Resize(height=HEIGHT, width=WIDTH),\n",
    "                A.HorizontalFlip(p=1),\n",
    "                A.Affine(rotate=270,p=3),]),\n",
    "\n",
    "        Compose([CLAHE(p=1),\n",
    "                A.Resize(height=HEIGHT, width=WIDTH),\n",
    "                A.ShiftScaleRotate(p=1),]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23639 validated image filenames.\n",
      "23639/23639 [==============================] - 1105s 47ms/step\n",
      "Found 23639 validated image filenames.\n",
      "23639/23639 [==============================] - 1110s 47ms/step\n",
      "Found 23639 validated image filenames.\n",
      "23639/23639 [==============================] - 1097s 46ms/step\n",
      "Found 23639 validated image filenames.\n",
      "23639/23639 [==============================] - 1098s 46ms/step\n",
      "Found 23639 validated image filenames.\n",
      "23639/23639 [==============================] - 1088s 46ms/step\n",
      "Found 23639 validated image filenames.\n",
      "23639/23639 [==============================] - 1095s 46ms/step\n",
      "Found 23639 validated image filenames.\n",
      "23639/23639 [==============================] - 1097s 46ms/step\n",
      "Found 23639 validated image filenames.\n",
      "23639/23639 [==============================] - 1095s 46ms/step\n",
      "Found 23639 validated image filenames.\n",
      "23639/23639 [==============================] - 1103s 47ms/step\n"
     ]
    }
   ],
   "source": [
    "reconstructed_model = tf.keras.models.load_model(MODEL_PATH)\n",
    "\n",
    "results_aggregated = np.zeros([23639,100],dtype=np.float32)\n",
    "results_collated = np.zeros([23639,100,len(TTA)],dtype=np.float32)\n",
    "\n",
    "submission = pd.read_csv(PATH+'sample_submission.csv')\n",
    "\n",
    "tta_df = pd.DataFrame(index=submission.index)\n",
    "\n",
    "for i, tta in enumerate(TTA):\n",
    "    test_gen = ImageDataAugmentor(augment=tta)\n",
    "    test_generator = test_gen.flow_from_dataframe(dataframe=submission,\n",
    "                                              directory=test_dir,\n",
    "                                              x_col='filename',\n",
    "                                              y_col=None,\n",
    "                                              target_size=(WIDTH,HEIGHT),\n",
    "                                              class_mode=None,\n",
    "                                              batch_size=1,\n",
    "                                              shuffle=False,)\n",
    "\n",
    "    STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "    STEP_SIZE_TEST,test_generator.n,test_generator.batch_size\n",
    "    \n",
    "    test_generator.reset()\n",
    "    # x= test_generator.next()\n",
    "    # image = x[0]\n",
    "    # plt.imshow(image/255)\n",
    "    # plt.show()  \n",
    "    # print(np.max(image),np.min(image))\n",
    "    results = reconstructed_model.predict(test_generator,verbose=1,steps=STEP_SIZE_TEST)\n",
    "    results_collated[:,:,i] = results\n",
    "    results_aggregated += results\n",
    "\n",
    "\n",
    "results_aggregated = results_aggregated/len(TTA)\n",
    "predicted_class_indices=np.argmax(results_aggregated,axis=1)\n",
    "\n",
    "labels_dict = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels_dict[k] for k in predicted_class_indices]\n",
    "\n",
    "filenames=test_generator.filenames\n",
    "submission=pd.DataFrame({\"Filename\":[filename.replace('all_classes/','')for filename in filenames],\n",
    "                      \"cultivar\":predictions})\n",
    "\n",
    "submission_name = save_dir+'submission-TTA-rot+rnd-EfficientNetV2L-imagenet-2022-04-30-124425.csv'\n",
    "submission.to_csv(submission_name,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Horizontal and Vertical Flips, Random Rotation and Colour Jitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TTA = [\n",
    "        Compose([CLAHE(p=1),\n",
    "                A.Resize(height=HEIGHT, width=WIDTH),]),\n",
    "\n",
    "        Compose([CLAHE(p=1),\n",
    "                A.Resize(height=HEIGHT, width=WIDTH),\n",
    "                A.HorizontalFlip(p=1),]),\n",
    "\n",
    "        Compose([CLAHE(p=1),\n",
    "                A.Resize(height=HEIGHT, width=WIDTH),\n",
    "                A.VerticalFlip(p=1),]),\n",
    "\n",
    "        Compose([CLAHE(p=1),\n",
    "                A.Resize(height=HEIGHT, width=WIDTH),\n",
    "                A.ShiftScaleRotate(p=1),]),\n",
    "        \n",
    "        Compose([CLAHE(p=1),\n",
    "                A.Resize(height=HEIGHT, width=WIDTH),\n",
    "                A.ColorJitter (brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2, p=1),]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23639 validated image filenames.\n",
      "23639/23639 [==============================] - 1549s 65ms/step\n"
     ]
    }
   ],
   "source": [
    "reconstructed_model = tf.keras.models.load_model(MODEL_PATH)\n",
    "\n",
    "results_aggregated = np.zeros([23639,100],dtype=np.float32)\n",
    "results_collated = np.zeros([23639,100,len(TTA)],dtype=np.float32)\n",
    "\n",
    "submission = pd.read_csv(PATH+'sample_submission.csv')\n",
    "\n",
    "tta_df = pd.DataFrame(index=submission.index)\n",
    "\n",
    "for i, tta in enumerate(TTA):\n",
    "    test_gen = ImageDataAugmentor(augment=tta)\n",
    "    test_generator = test_gen.flow_from_dataframe(dataframe=submission,\n",
    "                                              directory=test_dir,\n",
    "                                              x_col='filename',\n",
    "                                              y_col=None,\n",
    "                                              target_size=(WIDTH,HEIGHT),\n",
    "                                              class_mode=None,\n",
    "                                              batch_size=1,\n",
    "                                              shuffle=False,)\n",
    "\n",
    "    STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "    STEP_SIZE_TEST,test_generator.n,test_generator.batch_size\n",
    "    \n",
    "    # test_generator.reset()\n",
    "    # x= test_generator.next()\n",
    "    # image = x[0]\n",
    "    # plt.imshow(image/255)\n",
    "    # plt.show()  \n",
    "    # print(np.max(image),np.min(image))\n",
    "    results = reconstructed_model.predict(test_generator,verbose=1,steps=STEP_SIZE_TEST)\n",
    "    results_collated[:,:,i] = results\n",
    "    results_aggregated += results\n",
    "\n",
    "\n",
    "results_aggregated = results_aggregated/len(TTA)\n",
    "predicted_class_indices=np.argmax(results_aggregated,axis=1)\n",
    "\n",
    "labels_dict = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels_dict[k] for k in predicted_class_indices]\n",
    "\n",
    "filenames=test_generator.filenames\n",
    "submission=pd.DataFrame({\"Filename\":[filename.replace('all_classes/','')for filename in filenames],\n",
    "                      \"cultivar\":predictions})\n",
    "\n",
    "submission_name = save_dir+'submission-TTA-hfvfrndrot+jitter-EfficientNetV2L-imagenet-2022-04-30-124425.csv'\n",
    "submission.to_csv(submission_name,index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4f0f00476bf3a68144e5fe1ac7c732c5bd1bb6be96a0d4ae196528f0eb94dba7"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tf2_8_0')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
